----------------------------------------------------------------------------------------
Objectives
-----------------------------------------------------------------------------------------
Since we have studied PUS sequences in experiment E10 and E12, now we have a rough guess of how to manipulate the input parameters so that our algorithms might perform worse than they were. 

It is a common pattern shown by both experiments that as the distribution range grows wider, our algorithms have slightly higher competitive ratios. Thus we first want to examine this hypothesis by varying the distribution range (a, b) with the benevolent function f fixed.   

Besides, the change of performance of single-machine algorithms with respect to benevolent functions is different from that of two-machine algorithms. Single-machine algorithms tend to have the worst performance when the degree of polynomial is high; on the contrary, two-machine algorithms show the worst performance on the PUS sequences with linear benevolent function. For purpose of maximizing the competitive ratio, we will generate a set of PUS sequences with linear f for testing single-machine algorithms and the other set with nonlinear f for testing two-machine algorithms. 

-----------------------------------------------------------------------------------------
Procedures
-----------------------------------------------------------------------------------------

Create folders E16.1, E16.2, E16.3 ... E16.18. Copy and paste run1.sh and run2.sh from E12

We will stick to p = 0.5 and use different combinations of distribution range (a, b) and benevolent functions f to do the experiment. Each folder would use a distinct combination of (a,b) and f. For each combination, we will generate 10000 job sequences.

Use input files to reduce time of typing parameters since typing in command line is less convenient. After writing input files, place them in their according subdirectories and rename them as input. For exmaple, E16.2/input

Example input file(Input of E16.3):
1
0.5
1
100000
lambda y:y
10000
Y

Furthremore, generating job sequence should be automated. We use a bash file run1.sh to complete this process. We should use the bash file from E12 but modify it.
These are parameters used to generate the job sequences. The generated results will be stored in folder /jobs within subfolders. For example, E16.3/jobs

E16.1:
    a = 1
    b = 1000
    f = y
E16.2:
    a = 1
    b = 10000
    f = y
E16.3:
    a = 1
    b = 100000
    f = y
E16.4:
    a = 100
    b = 1000
    f = y
E16.5:
    a = 100
    b = 10000
    f = y
E16.6:
    a = 100
    b = 100000
    f = y
E16.7:
    a = 1000
    b = 10000
    f = y
E16.8:
    a = 1000
    b = 100000
    f = y
E16.9:
    a = 10000
    b = 100000
    f = y
E16.10:
    a = 1
    b = 1000
    f = y^3
E16.11:
    a = 1
    b = 10000
    f = y^3
E16.12:
    a = 1
    b = 100000
    f = y^3
E16.13:
    a = 100
    b = 1000
    f = y^3
E16.14:
    a = 100
    b = 10000
    f = y^3
E16.15:
    a = 100
    b = 100000
    f = y^3
E16.16:
    a = 1000
    b = 10000
    f = y^3
E16.17:
    a = 1000
    b = 100000
    f = y^3
E16.18:
    a = 10000
    b = 100000
    f = y^3

Ideally, most labor for extending this experiment in future will be done by modifying and running bash files
We will reuse the config files from E10 and E12. Rename them as config1, config2, ... config12

Modify bash file run2.sh to automate running simulation. It is supposed to run algorithms 1-3 on job sequences in job bases 1-9, run algorithms 4-12 on job sequences in job bases 10-18, and output result files to the proper directory with names being the index of algorithms. For example, when running algorithm 3 over job base 4, we expect the result residing in E16.4/result3  

Modify the script E12/clip.py to pick up results

---------------------------------------------------------------------------------------
Result
---------------------------------------------------------------------------------------

Comparison of competitive ratios across 3 single-machine algorithms are summerized below

(a,b) of job base    Greedy-2    Greedy-1.5     Greedy-4    
(1,1000)             1.46        1.30           1.92 
(1,10000)            1.31        1.17           1.75
(1,100000)           1.31        1.17           1.73
(100,1000)           1.44        1.28           1.92
(100,10000)          1.31        1.17           1.73
(100,100000)         1.31        1.17           1.73
(1000,10000)         1.31        1.17           1.75
(1000,100000)        1.31        1.17           1.75
(10000,100000)       1.31        1.17           1.72

Notice that f(y) = y. The CPU time spent on each experiment(each figure shown on the table) was about 1 minute.

Comparison of competitive ratios across 9 two-machine algorithms are summerized below

(a,b) of job base   FP(2,2) FP(1.5,4) FP(4,1.5) ABC(2,2) ABC(1.5,4) ABC(4,1.5) LVF(2,2) LVF(1.5,4) LVF(4,1.5) 
(1,1000)            1.27    1.35      1.33      1.27     1.34       1.34       1.26     1.33       1.33   
(1,10000)           1.27    1.35      1.33      1.27     1.33       1.33       1.26     1.33       1.33
(1,100000)          1.27    1.35      1.33      1.26     1.33       1.33       1.26     1.33       1.32
(100,1000)          1.27    1.36      1.33      1.27     1.34       1.34       1.27     1.34       1.33
(100,10000)         1.27    1.36      1.33      1.27     1.34       1.34       1.26     1.33       1.34
(100,100000)        1.27    1.35      1.33      1.26     1.34       1.34       1.26     1.33       1.33
(1000,10000)        1.27    1.36      1.33      1.27     1.34       1.34       1.27     1.33       1.33
(1000,100000)       1.27    1.36      1.33      1.27     1.34       1.34       1.26     1.33       1.33
(10000,100000)      1.27    1.36      1.34      1.27     1.34       1.34       1.27     1.33       1.34

Note that f(y) = y^3. The CPU time spent on each experiment(each figure shown on the table) was between 4 and 5 minute.

From simple observation of the results, our hypothesis that competitive ratio of our proposed algorithms is positively related to the width of distribution range (a, b) is basically invalidated. There is no clear relation between competitive ratio and (a, b). 

Also, this experiment confirms the stability of our algorithms with respect to change of PUS input parameters. It offers extra confidence to the performance of our algorithms. 
